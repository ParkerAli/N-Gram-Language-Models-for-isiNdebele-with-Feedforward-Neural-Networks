{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1268,
     "status": "ok",
     "timestamp": 1624277145262,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "UwDH8EIaXGk4",
    "outputId": "696b0e12-1826-4050-ac3f-74803b4c799f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 21 12:05:43 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   64C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi # check which GPU we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtevwEeaU-wV"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3317,
     "status": "ok",
     "timestamp": 1624277153910,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "FrdTblcWHs14"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import islice\n",
    "\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.layers import Embedding, Dense, Dropout, Flatten\n",
    "from keras import Sequential \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22209,
     "status": "ok",
     "timestamp": 1624277176095,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "d765IdmYBdHL",
    "outputId": "1ffa1f04-93db-4391-dad2-44ccd269b0d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bD-XQIgUVFd7"
   },
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1643,
     "status": "ok",
     "timestamp": 1624277181033,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "Jd7cF09_IGy2"
   },
   "outputs": [],
   "source": [
    "DIRECTORY = \"\" \n",
    "\n",
    "class Sentences(object):\n",
    "\n",
    "    def __init__(self,filename, vocab = None) -> None:\n",
    "        self.filename = filename\n",
    "        if vocab is None:\n",
    "          self.vocab = self.unk_handling(1)\n",
    "        else: \n",
    "          self.vocab = vocab\n",
    "        self.hash_to_word = defaultdict(lambda:\"<UNK>\")\n",
    "\n",
    "    def unk_handling(self,threshold):\n",
    "        counter = Counter()\n",
    "        with open(DIRECTORY+self.filename,\"rb\") as file:\n",
    "            for sentence in file:\n",
    "                counter.update(Counter(str(sentence).lower().translate(str.maketrans('','',string.punctuation)).split()))\n",
    "\n",
    "        return {k for k,c in counter.items() if c > threshold}\n",
    "\n",
    "    def __iter__(self):\n",
    "        vocab_length = len(self.vocab)+2\n",
    "        with open(DIRECTORY + self.filename,\"rb\") as file:\n",
    "            for sentence in file:\n",
    "              encoded_arr = [one_hot(\"<s>\",vocab_length)[0]]\n",
    "              for word in [word if word in self.vocab else \"<UNK>\" for word in str(sentence).lower().translate(str.maketrans('','',string.punctuation)).split()]:\n",
    "                  hashed_word = one_hot(word,vocab_length)\n",
    "                  self.hash_to_word[hashed_word[0]] = word\n",
    "                  encoded_arr.append(hashed_word[0])\n",
    "              yield np.array(encoded_arr)\n",
    "\n",
    "def subseqs(seq,window_length):\n",
    "  return np.fromfunction(lambda i, j: seq[i + j], (len(seq) - window_length + 1, window_length),dtype=int)\n",
    "\n",
    "train_sentences = Sentences(\"nchlt_text.nr.train\")\n",
    "val_sentences = Sentences(\"nchlt_text.nr.valid\", train_sentences.vocab)\n",
    "test_sentences = Sentences(\"nchlt_text.nr.test\", train_sentences.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8924,
     "status": "ok",
     "timestamp": 1624277189952,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "G7KNTJsZPrGx"
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "\n",
    "window_length = 3\n",
    "\n",
    "for vec in train_sentences:\n",
    "  train.extend(subseqs(vec,window_length))\n",
    "for vec in val_sentences:\n",
    "  val.extend(subseqs(vec,window_length))\n",
    "for vec in test_sentences:\n",
    "  test.extend(subseqs(vec,window_length))\n",
    "\n",
    "train = pd.DataFrame(train)\n",
    "val = pd.DataFrame(val)\n",
    "test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1624277194952,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "r7wfhdSRzs_N"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(train.iloc[:,0:window_length-1])\n",
    "y_train = np.array(train.iloc[:,window_length-1])\n",
    "\n",
    "X_val = np.array(val.iloc[:,0:window_length-1])\n",
    "y_val = np.array(val.iloc[:,window_length-1])\n",
    "\n",
    "X_test = np.array(test.iloc[:,0:window_length-1])\n",
    "y_test = np.array(test.iloc[:,window_length-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1624262656390,
     "user": {
      "displayName": "Mahmood-Ali Parker",
      "photoUrl": "",
      "userId": "06278977309529691111"
     },
     "user_tz": -120
    },
    "id": "pBRgn8A2Sla7",
    "outputId": "603ea32d-d65d-40eb-b378-73b1b557159c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36325, 35579],\n",
       "       [35579, 55139],\n",
       "       [55139, 35730],\n",
       "       ...,\n",
       "       [32456, 47347],\n",
       "       [47347, 56996],\n",
       "       [56996, 15477]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDWqYKAeVMLG"
   },
   "source": [
    "### Baseline Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1624277197700,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "y4G2_jZHWzpu",
    "outputId": "ba2c4a95-704a-4abe-8d70-b84341f1e752"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58108"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(train_sentences.vocab)+2\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1624277197701,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "YFvZx--lfwxC"
   },
   "outputs": [],
   "source": [
    "# Perplexity metric\n",
    "def perplexity(y_true, y_pred):\n",
    "   scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "   perplexity = K.exp(scce(y_true, y_pred))\n",
    "   return perplexity\n",
    "\n",
    "\n",
    "custom_early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=2, \n",
    "    min_delta=0.0001 # amount of change to quantify an improvement\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5717,
     "status": "ok",
     "timestamp": 1624277204488,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "AZb7sMFFXspV",
    "outputId": "4bdd3f73-819e-4f46-e26c-97e4fc26c0be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 2, 1000)           58108000  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2049024   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 58108)             119063292 \n",
      "=================================================================\n",
      "Total params: 181,319,516\n",
      "Trainable params: 181,319,516\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 1000, input_length=window_length-1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2048, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', # defualt params of [learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False]\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy', perplexity])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1624277204490,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "gVem8DjPis9O"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9063565,
     "status": "ok",
     "timestamp": 1624286268046,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "_47PwOM8iRFc",
    "outputId": "11dfb679-eb7e-480d-89a2-60992f929c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 240s 1s/step - loss: 9.3896 - accuracy: 0.0678 - perplexity: 17819.2820 - val_loss: 8.0292 - val_accuracy: 0.1140 - val_perplexity: 3180.3977\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 226s 2s/step - loss: 8.2591 - accuracy: 0.0859 - perplexity: 3888.9712 - val_loss: 7.2974 - val_accuracy: 0.1421 - val_perplexity: 1557.8829\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 223s 1s/step - loss: 7.3303 - accuracy: 0.1284 - perplexity: 1540.9905 - val_loss: 6.3834 - val_accuracy: 0.1772 - val_perplexity: 665.6235\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 223s 1s/step - loss: 6.1748 - accuracy: 0.1869 - perplexity: 483.7538 - val_loss: 5.5151 - val_accuracy: 0.2189 - val_perplexity: 304.8610\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 223s 1s/step - loss: 4.9640 - accuracy: 0.2693 - perplexity: 143.4530 - val_loss: 4.7634 - val_accuracy: 0.2734 - val_perplexity: 148.6217\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 222s 1s/step - loss: 3.9638 - accuracy: 0.3633 - perplexity: 52.7531 - val_loss: 4.1359 - val_accuracy: 0.3202 - val_perplexity: 76.7158\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 222s 1s/step - loss: 3.2976 - accuracy: 0.4368 - perplexity: 27.1412 - val_loss: 3.6229 - val_accuracy: 0.3759 - val_perplexity: 44.2103\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 221s 1s/step - loss: 2.8471 - accuracy: 0.4885 - perplexity: 17.3106 - val_loss: 3.2133 - val_accuracy: 0.4230 - val_perplexity: 28.4470\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 222s 1s/step - loss: 2.5206 - accuracy: 0.5273 - perplexity: 12.5002 - val_loss: 2.8983 - val_accuracy: 0.4635 - val_perplexity: 20.3268\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 222s 1s/step - loss: 2.2830 - accuracy: 0.5565 - perplexity: 9.8506 - val_loss: 2.6422 - val_accuracy: 0.4977 - val_perplexity: 15.4488\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 221s 1s/step - loss: 2.0980 - accuracy: 0.5798 - perplexity: 8.1853 - val_loss: 2.4676 - val_accuracy: 0.5230 - val_perplexity: 12.8256\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.9720 - accuracy: 0.5963 - perplexity: 7.2158 - val_loss: 2.3237 - val_accuracy: 0.5424 - val_perplexity: 10.9800\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 221s 1s/step - loss: 1.8582 - accuracy: 0.6100 - perplexity: 6.4402 - val_loss: 2.2160 - val_accuracy: 0.5579 - val_perplexity: 9.8174\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.7695 - accuracy: 0.6223 - perplexity: 5.8965 - val_loss: 2.1273 - val_accuracy: 0.5685 - val_perplexity: 8.9362\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.7079 - accuracy: 0.6301 - perplexity: 5.5364 - val_loss: 2.0564 - val_accuracy: 0.5778 - val_perplexity: 8.3165\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.6448 - accuracy: 0.6391 - perplexity: 5.1990 - val_loss: 1.9951 - val_accuracy: 0.5892 - val_perplexity: 7.8045\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 222s 1s/step - loss: 1.5993 - accuracy: 0.6447 - perplexity: 4.9671 - val_loss: 1.9479 - val_accuracy: 0.5947 - val_perplexity: 7.4266\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 221s 1s/step - loss: 1.5623 - accuracy: 0.6498 - perplexity: 4.7852 - val_loss: 1.9051 - val_accuracy: 0.5993 - val_perplexity: 7.1395\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.5232 - accuracy: 0.6550 - perplexity: 4.6036 - val_loss: 1.8780 - val_accuracy: 0.6009 - val_perplexity: 6.9255\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.4965 - accuracy: 0.6591 - perplexity: 4.4796 - val_loss: 1.8453 - val_accuracy: 0.6042 - val_perplexity: 6.7169\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.4692 - accuracy: 0.6615 - perplexity: 4.3604 - val_loss: 1.8212 - val_accuracy: 0.6070 - val_perplexity: 6.5358\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.4461 - accuracy: 0.6652 - perplexity: 4.2592 - val_loss: 1.8021 - val_accuracy: 0.6088 - val_perplexity: 6.4176\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 221s 1s/step - loss: 1.4203 - accuracy: 0.6693 - perplexity: 4.1505 - val_loss: 1.7829 - val_accuracy: 0.6103 - val_perplexity: 6.2971\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 221s 1s/step - loss: 1.4055 - accuracy: 0.6695 - perplexity: 4.0880 - val_loss: 1.7693 - val_accuracy: 0.6141 - val_perplexity: 6.2012\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.3843 - accuracy: 0.6729 - perplexity: 4.0032 - val_loss: 1.7557 - val_accuracy: 0.6128 - val_perplexity: 6.1266\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.3764 - accuracy: 0.6728 - perplexity: 3.9706 - val_loss: 1.7411 - val_accuracy: 0.6150 - val_perplexity: 6.0557\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.3593 - accuracy: 0.6748 - perplexity: 3.9022 - val_loss: 1.7290 - val_accuracy: 0.6161 - val_perplexity: 5.9576\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.3446 - accuracy: 0.6779 - perplexity: 3.8472 - val_loss: 1.7205 - val_accuracy: 0.6188 - val_perplexity: 5.9192\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 219s 1s/step - loss: 1.3305 - accuracy: 0.6798 - perplexity: 3.7925 - val_loss: 1.7117 - val_accuracy: 0.6189 - val_perplexity: 5.8819\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 219s 1s/step - loss: 1.3206 - accuracy: 0.6810 - perplexity: 3.7538 - val_loss: 1.7015 - val_accuracy: 0.6194 - val_perplexity: 5.7977\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 221s 1s/step - loss: 1.3118 - accuracy: 0.6817 - perplexity: 3.7208 - val_loss: 1.6935 - val_accuracy: 0.6197 - val_perplexity: 5.7686\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.3020 - accuracy: 0.6828 - perplexity: 3.6849 - val_loss: 1.6873 - val_accuracy: 0.6217 - val_perplexity: 5.7350\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 219s 1s/step - loss: 1.2888 - accuracy: 0.6840 - perplexity: 3.6371 - val_loss: 1.6808 - val_accuracy: 0.6223 - val_perplexity: 5.7022\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 219s 1s/step - loss: 1.2849 - accuracy: 0.6852 - perplexity: 3.6221 - val_loss: 1.6847 - val_accuracy: 0.6227 - val_perplexity: 5.7336\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 219s 1s/step - loss: 1.2715 - accuracy: 0.6863 - perplexity: 3.5753 - val_loss: 1.6774 - val_accuracy: 0.6222 - val_perplexity: 5.6978\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 218s 1s/step - loss: 1.2640 - accuracy: 0.6877 - perplexity: 3.5473 - val_loss: 1.6731 - val_accuracy: 0.6230 - val_perplexity: 5.6668\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.2625 - accuracy: 0.6874 - perplexity: 3.5406 - val_loss: 1.6736 - val_accuracy: 0.6237 - val_perplexity: 5.6765\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 219s 1s/step - loss: 1.2504 - accuracy: 0.6890 - perplexity: 3.5001 - val_loss: 1.6643 - val_accuracy: 0.6225 - val_perplexity: 5.6162\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 219s 1s/step - loss: 1.2525 - accuracy: 0.6880 - perplexity: 3.5055 - val_loss: 1.6593 - val_accuracy: 0.6256 - val_perplexity: 5.5978\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 220s 1s/step - loss: 1.2405 - accuracy: 0.6901 - perplexity: 3.4643 - val_loss: 1.6615 - val_accuracy: 0.6231 - val_perplexity: 5.6198\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 221s 1s/step - loss: 1.2335 - accuracy: 0.6908 - perplexity: 3.4408 - val_loss: 1.6598 - val_accuracy: 0.6252 - val_perplexity: 5.6074\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model_history = model.fit(x = X_train, \n",
    "                                y = y_train, \n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                validation_data = (X_val,y_val),\n",
    "                                callbacks=[custom_early_stopping],\n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3141,
     "status": "ok",
     "timestamp": 1624286271603,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "l8Yt-GU1oZrR"
   },
   "outputs": [],
   "source": [
    "model_structure=model.to_json()\n",
    "f = Path(\"/content/drive/My Drive/NLP A2/trigram_structure.json\")\n",
    "f.write_text(model_structure)\n",
    "model.save_weights('/content/drive/My Drive/NLP A2/trigram.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iw0ZlzoBplgb"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/My Drive/NLP A2/trigram.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13283,
     "status": "ok",
     "timestamp": 1624286842210,
     "user": {
      "displayName": "yes no",
      "photoUrl": "",
      "userId": "14719513706694747807"
     },
     "user_tz": -120
    },
    "id": "iidnGiWrVRNU",
    "outputId": "73ff14f7-3013-4cd8-beb9-d55d2fa6f571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 8.757308\n",
      "Accuracy: 60.357952\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy, perplexity = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Perplexity: %f' % (np.exp(loss)))\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "trigram.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
